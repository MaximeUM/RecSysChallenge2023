{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "\n",
    "from shutil import rmtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(2023)\n",
    "import random\n",
    "random.seed(2023)\n",
    "np.random.seed(2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chckpt_path = './models/'\n",
    "results_path = './results/'\n",
    "if os.path.exists(chckpt_path):\n",
    "    rmtree(chckpt_path)\n",
    "if os.path.exists(results_path):\n",
    "    rmtree(results_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/train/\"\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "data = pd.concat((pd.read_csv(f, sep=\"\\t\") for f in all_files), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(data, test_size=0.25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_train = train_data.iloc[:,2:33]\n",
    "del cat_train[\"f_7\"] #Only one value --> useless\n",
    "bin_train = train_data.iloc[:,33:42]\n",
    "num_train = train_data.iloc[:,42:80]\n",
    "labels_train = train_data.iloc[:,80:82]\n",
    "\n",
    "cat_val = val_data.iloc[:,2:33]\n",
    "del cat_val[\"f_7\"] #Only one value --> useless\n",
    "bin_val = val_data.iloc[:,33:42]\n",
    "num_val = val_data.iloc[:,42:80]\n",
    "labels_val = val_data.iloc[:,80:82]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical variables\n",
    "cat_train_selected = cat_train.to_numpy()\n",
    "cat_val_selected = cat_val.to_numpy()\n",
    "\n",
    "# Numerical variables : estimate missing values and normalize \n",
    "imputer = IterativeImputer(max_iter=10, random_state=0)\n",
    "num_train_selected = imputer.fit_transform(num_train)\n",
    "scaler = MinMaxScaler()\n",
    "num_train_selected = scaler.fit_transform(num_train_selected)\n",
    "\n",
    "num_val_selected = scaler.transform(imputer.transform(num_val))\n",
    "\n",
    "# Binary variables\n",
    "bin_train_selected = bin_train.to_numpy()\n",
    "bin_val_selected = bin_val.to_numpy()\n",
    "\n",
    "# Output variables\n",
    "y_train = labels_train\n",
    "y_val = labels_val\n",
    "# y_is_clicked = y.iloc[:,0]\n",
    "y_train_is_installed = y_train.iloc[:,1]\n",
    "y_val_is_installed = y_val.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col_ind in range(cat_train_selected.shape[1]):\n",
    "\n",
    "    unique_values = np.unique(cat_train_selected[:, col_ind][~np.isnan(cat_train_selected[:,col_ind])]).astype(int)\n",
    "    # test_unique_values = np.unique(cat_test_selected[:, col_ind]).astype(int)\n",
    "\n",
    "    # Make categorical variables from 1 to n (n corresponding to the number of unique values for the corresponding categorical feature)\n",
    "    replacement_dict = dict()\n",
    "    for index, val in enumerate(unique_values):\n",
    "        index+=1\n",
    "        replacement_dict[val] = index\n",
    "\n",
    "    # Process training data (categorical)\n",
    "    for line_ind in range(len(cat_train_selected[:,col_ind])):\n",
    "        if math.isnan(cat_train_selected[line_ind, col_ind]): # 0 used for missing values\n",
    "            cat_train_selected[line_ind, col_ind] = 0\n",
    "        else:\n",
    "            cat_train_selected[line_ind, col_ind] = replacement_dict[int(cat_train_selected[line_ind, col_ind])] # Use the new value (from 1 to n)\n",
    "\n",
    "    # Process validation data (categorical)\n",
    "    for line_ind in range(len(cat_val_selected[:,col_ind])):\n",
    "        try:\n",
    "            if math.isnan(cat_val_selected[line_ind, col_ind]):\n",
    "                cat_val_selected[line_ind, col_ind] = 0 # 0 used for missing values\n",
    "            else:\n",
    "                cat_val_selected[line_ind, col_ind] = replacement_dict[int(cat_val_selected[line_ind, col_ind])] # Use the new value (from 1 to n)\n",
    "        except KeyError:\n",
    "            cat_val_selected[line_ind, col_ind] = 0 # If the value was not in the training data, treat as a missing value (because we can't train on it)\n",
    "\n",
    "cat_train_selected = cat_train_selected.astype(int)\n",
    "cat_val_selected = cat_val_selected.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples:\n",
      "    Total: 2614389\n",
      "    Positive: 455360 (17.42% of total)\n",
      "\n",
      "[-1.55632555]\n"
     ]
    }
   ],
   "source": [
    "# Compute bias to help the model with imbalanced dataset\n",
    "neg, pos = np.bincount(y_train_is_installed) \n",
    "total = neg + pos \n",
    "print('Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format( total, pos, 100 * pos / total)) \n",
    "initial_bias = np.log([pos/neg]) \n",
    "print(initial_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "embed_size = 256\n",
    "\n",
    "# Inputs\n",
    "cat_input_layer = layers.Input(shape=(cat_train_selected.shape[1],), dtype=tf.int64)\n",
    "bin_input_layer = layers.Input(shape=(bin_train_selected.shape[1],), dtype=tf.int64)\n",
    "num_input_layer = layers.Input(shape=(num_train_selected.shape[1],), dtype=tf.float64)\n",
    "\n",
    "embedding_layers = []\n",
    "for i in range(cat_train_selected.shape[1]):\n",
    "    num_values = len(set(cat_train_selected[:,i]))\n",
    "    if num_values <= embed_size:\n",
    "        embedding_layers.append(layers.Embedding(input_dim=num_values+1, output_dim=num_values, input_length=1, mask_zero=True)(cat_input_layer[:,i]))\n",
    "    else:\n",
    "        embedding_layers.append(layers.Embedding(input_dim=num_values+1, output_dim=embed_size, input_length=1, mask_zero=True)(cat_input_layer[:,i]))\n",
    "\n",
    "bin_dense_layer = layers.Dense(64, activation='relu')(bin_input_layer)\n",
    "num_dense_layer = layers.Dense(64, activation='relu')(num_input_layer)\n",
    "\n",
    "# Concat all inputs\n",
    "concatted = tf.keras.layers.Concatenate()([bin_dense_layer, num_dense_layer, *embedding_layers])\n",
    "\n",
    "# Hidden layers\n",
    "hidden_layer_1 = layers.Dense(500, activation='relu')(concatted)\n",
    "hidden_layer_2 = layers.Dense(250, activation='relu')(hidden_layer_1)\n",
    "hidden_layer_3 = layers.Dense(50, activation='relu')(hidden_layer_2)\n",
    "hidden_layer_4 = layers.Dense(100, activation='relu')(hidden_layer_3)\n",
    "hidden_layer_5 = layers.Dense(40, activation='relu')(hidden_layer_4)\n",
    "\n",
    "# Outputs\n",
    "output_bias = tf.keras.initializers.Constant(initial_bias)\n",
    "\n",
    "#output_1 = layers.Dense(1, activation='sigmoid', name=\"is_clicked\", bias_initializer=output_bias)(hidden_layer_5) # If we want to predict \"is_clicked\", use this output (give two outputs to the model instead of one).\n",
    "output_2 = layers.Dense(1, activation=\"sigmoid\", name=\"is_installed\", bias_initializer=output_bias)(hidden_layer_5)\n",
    "\n",
    "# Create model\n",
    "model = keras.Model(inputs=[cat_input_layer, bin_input_layer, num_input_layer], outputs=[output_2])\n",
    "# model = keras.Model(inputs=[cat_input_layer, bin_input_layer, num_input_layer], outputs=[output_1, output_2]) # If we want to predict \"is_clicked\" and \"is_installed\"\n",
    "\n",
    "# Compile model\n",
    "batch_size = 5000 \n",
    "learning_rate=0.001\n",
    "optimizer = keras.optimizers.Adam(lr=learning_rate)\n",
    "\n",
    "if len(model.outputs)>1:\n",
    "    monitor_name = 'val_is_installed_loss'\n",
    "else:\n",
    "    monitor_name = \"val_loss\"\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=monitor_name, patience=3)\n",
    "mcp_save = tf.keras.callbacks.ModelCheckpoint(filepath= chckpt_path + '{epoch:04d}', save_best_only=True, save_weights_only=False, monitor='val_loss', mode='min', save_freq='epoch')\n",
    "# mcp_save = tf.keras.callbacks.ModelCheckpoint(filepath= chckpt_path + '{epoch:04d}', save_best_only=False, save_weights_only=False, monitor='val_loss', mode='min', save_freq='epoch')\n",
    "\n",
    "acc = tf.metrics.BinaryAccuracy(threshold=0.5)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy', acc])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "523/523 [==============================] - ETA: 0s - loss: 0.3569 - accuracy: 0.8461 - binary_accuracy: 0.8461INFO:tensorflow:Assets written to: ./models/0001/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/0001/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "523/523 [==============================] - 45s 82ms/step - loss: 0.3569 - accuracy: 0.8461 - binary_accuracy: 0.8461 - val_loss: 0.3287 - val_accuracy: 0.8582 - val_binary_accuracy: 0.8582\n",
      "Epoch 2/50\n",
      "523/523 [==============================] - ETA: 0s - loss: 0.3199 - accuracy: 0.8623 - binary_accuracy: 0.8623INFO:tensorflow:Assets written to: ./models/0002/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/0002/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "523/523 [==============================] - 42s 81ms/step - loss: 0.3199 - accuracy: 0.8623 - binary_accuracy: 0.8623 - val_loss: 0.3195 - val_accuracy: 0.8636 - val_binary_accuracy: 0.8636\n",
      "Epoch 3/50\n",
      "523/523 [==============================] - ETA: 0s - loss: 0.3106 - accuracy: 0.8660 - binary_accuracy: 0.8660INFO:tensorflow:Assets written to: ./models/0003/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/0003/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "523/523 [==============================] - 43s 82ms/step - loss: 0.3106 - accuracy: 0.8660 - binary_accuracy: 0.8660 - val_loss: 0.3177 - val_accuracy: 0.8646 - val_binary_accuracy: 0.8646\n",
      "Epoch 4/50\n",
      "523/523 [==============================] - 40s 76ms/step - loss: 0.3022 - accuracy: 0.8696 - binary_accuracy: 0.8696 - val_loss: 0.3200 - val_accuracy: 0.8631 - val_binary_accuracy: 0.8631\n",
      "Epoch 5/50\n",
      "523/523 [==============================] - 40s 76ms/step - loss: 0.2931 - accuracy: 0.8736 - binary_accuracy: 0.8736 - val_loss: 0.3242 - val_accuracy: 0.8631 - val_binary_accuracy: 0.8631\n",
      "Epoch 6/50\n",
      "523/523 [==============================] - 41s 78ms/step - loss: 0.2828 - accuracy: 0.8782 - binary_accuracy: 0.8782 - val_loss: 0.3303 - val_accuracy: 0.8604 - val_binary_accuracy: 0.8604\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2da49ee20>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit((cat_train_selected, bin_train_selected, num_train_selected), y_train_is_installed, epochs = 50, batch_size=batch_size, \n",
    "          validation_data=((cat_val_selected, bin_val_selected, num_val_selected), y_val_is_installed),\n",
    "          callbacks=[early_stopping, mcp_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_models= glob.glob(chckpt_path+\"/*\") \n",
    "latest_model = max(list_of_models, key=os.path.getctime)\n",
    "# print(latest_file)\n",
    "model = tf.keras.models.load_model(latest_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(y_true, y_pred):\n",
    "    y_pred[y_pred>=0.5]=1\n",
    "    y_pred[y_pred<0.5]=0\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "    tpr = round(tp / (tp+fn),4)\n",
    "    fpr = round(tp / (fp+tn),4)\n",
    "    tnr = round(tn / (tn+fp),4)\n",
    "    fnr = round(fn / (fn+tp),4)\n",
    "    acc = round((tp + tn) / (tp+fn+fp+tn),4)\n",
    "    precision = round(tp / (tp + fp),4)\n",
    "    f1 = round(2 * (precision * tpr) / (precision + tpr),4)\n",
    "    \n",
    "    return tpr, fpr, tnr, fnr, acc, precision, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175/175 [==============================] - 5s 25ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jr/974ggbdj74sczwq4lflylfy00000gn/T/ipykernel_22287/2816523072.py:14: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = round(tp / (tp + fp),4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "523/523 [==============================] - 13s 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jr/974ggbdj74sczwq4lflylfy00000gn/T/ipykernel_22287/2816523072.py:14: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = round(tp / (tp + fp),4)\n"
     ]
    }
   ],
   "source": [
    "# Val predictions\n",
    "y_pred_val = model.predict((cat_val_selected, bin_val_selected, num_val_selected), batch_size=batch_size)\n",
    "tpr_val, fpr_val, tnr_val, fnr_val, acc_val, precision_val, f1_val = compute_metrics(y_val_is_installed, y_pred_val)\n",
    "\n",
    "\n",
    "# Val dumb predictions\n",
    "y_pred_val_dumb = np.zeros(y_val_is_installed.shape)\n",
    "tpr_val_dumb, fpr_val_dumb, tnr_val_dumb, fnr_val_dumb, acc_val_dumb, precision_val_dumb, f1_val_dumb = compute_metrics(y_val_is_installed, y_pred_val_dumb)\n",
    "\n",
    "# Train predictions\n",
    "y_pred_train = model.predict((cat_train_selected, bin_train_selected, num_train_selected), batch_size=batch_size)\n",
    "tpr_train, fpr_train, tnr_train, fnr_train, acc_train, precision_train, f1_train = compute_metrics(y_train_is_installed, y_pred_train)\n",
    "\n",
    "# Train dumb predictions\n",
    "y_pred_train_dumb = np.zeros(y_train_is_installed.shape)\n",
    "tpr_train_dumb, fpr_train_dumb, tnr_train_dumb, fnr_train_dumb, acc_train_dumb, precision_train_dumb, f1_train_dumb = compute_metrics(y_train_is_installed, y_pred_train_dumb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5324, 0.1118, 0.8812, 0.4676, 0.8207, 0.4849, 0.5075, 0.8265)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpr_val, fpr_val, tnr_val, fnr_val, acc_val, precision_val, f1_val, acc_val_dumb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5425, 0.1144, 0.883, 0.4575, 0.8237, 0.4943, 0.5173, 0.8258)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpr_train, fpr_train, tnr_train, fnr_train, acc_train, precision_train, f1_train, acc_train_dumb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
