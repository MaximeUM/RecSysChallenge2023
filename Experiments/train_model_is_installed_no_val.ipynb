{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "\n",
    "from shutil import rmtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(2023)\n",
    "import random\n",
    "random.seed(2023)\n",
    "np.random.seed(2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chckpt_path = './models/'\n",
    "results_path = './results/'\n",
    "if os.path.exists(chckpt_path):\n",
    "    rmtree(chckpt_path)\n",
    "if os.path.exists(results_path):\n",
    "    rmtree(results_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/train/\"\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "data = pd.concat((pd.read_csv(f, sep=\"\\t\") for f in all_files), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_train = train_data.iloc[:,2:33]\n",
    "del cat_train[\"f_7\"] #Only one value --> useless\n",
    "bin_train = train_data.iloc[:,33:42]\n",
    "num_train = train_data.iloc[:,42:80]\n",
    "labels_train = train_data.iloc[:,80:82]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical variables\n",
    "cat_train_selected = cat_train.to_numpy()\n",
    "\n",
    "# Numerical variables : estimate missing values and normalize \n",
    "imputer = IterativeImputer(max_iter=10, random_state=0)\n",
    "num_train_selected = imputer.fit_transform(num_train)\n",
    "scaler = MinMaxScaler()\n",
    "num_train_selected = scaler.fit_transform(num_train_selected)\n",
    "\n",
    "# Binary variables\n",
    "bin_train_selected = bin_train.to_numpy()\n",
    "\n",
    "# Output variables\n",
    "y_train = labels_train\n",
    "y_train_is_installed = y_train.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col_ind in range(cat_train_selected.shape[1]):\n",
    "\n",
    "    unique_values = np.unique(cat_train_selected[:, col_ind][~np.isnan(cat_train_selected[:,col_ind])]).astype(int)\n",
    "\n",
    "    # Make categorical variables from 1 to n (n corresponding to the number of unique values for the corresponding categorical feature)\n",
    "    replacement_dict = dict()\n",
    "    for index, val in enumerate(unique_values):\n",
    "        index+=1\n",
    "        replacement_dict[val] = index\n",
    "\n",
    "    # Process training data (categorical)\n",
    "    for line_ind in range(len(cat_train_selected[:,col_ind])):\n",
    "        if math.isnan(cat_train_selected[line_ind, col_ind]): # 0 used for missing values\n",
    "            cat_train_selected[line_ind, col_ind] = 0\n",
    "        else:\n",
    "            cat_train_selected[line_ind, col_ind] = replacement_dict[int(cat_train_selected[line_ind, col_ind])] # Use the new value (from 1 to n)\n",
    "\n",
    "cat_train_selected = cat_train_selected.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples:\n",
      "    Total: 3485852\n",
      "    Positive: 606602 (17.40% of total)\n",
      "\n",
      "[-1.55741223]\n"
     ]
    }
   ],
   "source": [
    "# Compute bias to help the model with imbalanced dataset\n",
    "neg, pos = np.bincount(y_train_is_installed) \n",
    "total = neg + pos \n",
    "print('Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format( total, pos, 100 * pos / total)) \n",
    "initial_bias = np.log([pos/neg]) \n",
    "print(initial_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "embed_size = 256\n",
    "\n",
    "# Inputs\n",
    "cat_input_layer = layers.Input(shape=(cat_train_selected.shape[1],), dtype=tf.int64)\n",
    "bin_input_layer = layers.Input(shape=(bin_train_selected.shape[1],), dtype=tf.int64)\n",
    "num_input_layer = layers.Input(shape=(num_train_selected.shape[1],), dtype=tf.float64)\n",
    "\n",
    "embedding_layers = []\n",
    "for i in range(cat_train_selected.shape[1]):\n",
    "    num_values = len(set(cat_train_selected[:,i]))\n",
    "    if num_values <= embed_size:\n",
    "        embedding_layers.append(layers.Embedding(input_dim=num_values+1, output_dim=num_values, input_length=1, mask_zero=True)(cat_input_layer[:,i]))\n",
    "    else:\n",
    "        embedding_layers.append(layers.Embedding(input_dim=num_values+1, output_dim=embed_size, input_length=1, mask_zero=True)(cat_input_layer[:,i]))\n",
    "\n",
    "bin_dense_layer = layers.Dense(64, activation='relu')(bin_input_layer)\n",
    "num_dense_layer = layers.Dense(64, activation='relu')(num_input_layer)\n",
    "\n",
    "# Concat all inputs\n",
    "concatted = tf.keras.layers.Concatenate()([bin_dense_layer, num_dense_layer, *embedding_layers])\n",
    "\n",
    "# Hidden layers\n",
    "hidden_layer_1 = layers.Dense(500, activation='relu')(concatted)\n",
    "hidden_layer_2 = layers.Dense(250, activation='relu')(hidden_layer_1)\n",
    "hidden_layer_3 = layers.Dense(50, activation='relu')(hidden_layer_2)\n",
    "hidden_layer_4 = layers.Dense(100, activation='relu')(hidden_layer_3)\n",
    "hidden_layer_5 = layers.Dense(40, activation='relu')(hidden_layer_4)\n",
    "\n",
    "# Outputs\n",
    "output_bias = tf.keras.initializers.Constant(initial_bias)\n",
    "\n",
    "#output_1 = layers.Dense(1, activation='sigmoid', name=\"is_clicked\", bias_initializer=output_bias)(hidden_layer_5) # If we want to predict \"is_clicked\", use this output (give two outputs to the model instead of one).\n",
    "output_2 = layers.Dense(1, activation=\"sigmoid\", name=\"is_installed\", bias_initializer=output_bias)(hidden_layer_5)\n",
    "\n",
    "# Create model\n",
    "model = keras.Model(inputs=[cat_input_layer, bin_input_layer, num_input_layer], outputs=[output_2])\n",
    "# model = keras.Model(inputs=[cat_input_layer, bin_input_layer, num_input_layer], outputs=[output_1, output_2]) # If we want to predict \"is_clicked\" and \"is_installed\"\n",
    "\n",
    "# Compile model\n",
    "batch_size = 5000 \n",
    "learning_rate=0.001\n",
    "optimizer = keras.optimizers.Adam(lr=learning_rate)\n",
    "\n",
    "if len(model.outputs)>1:\n",
    "    monitor_name = 'val_is_installed_loss'\n",
    "else:\n",
    "    monitor_name = \"val_loss\"\n",
    "# early_stopping = tf.keras.callbacks.EarlyStopping(monitor=monitor_name, patience=3)\n",
    "mcp_save = tf.keras.callbacks.ModelCheckpoint(filepath= chckpt_path + '{epoch:04d}', save_best_only=False, save_weights_only=False, save_freq='epoch')\n",
    "\n",
    "acc = tf.metrics.BinaryAccuracy(threshold=0.5)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy', acc])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "697/698 [============================>.] - ETA: 0s - loss: 0.3499 - accuracy: 0.8494 - binary_accuracy: 0.8494INFO:tensorflow:Assets written to: ./models/0001/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/0001/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "698/698 [==============================] - 54s 75ms/step - loss: 0.3499 - accuracy: 0.8494 - binary_accuracy: 0.8494\n",
      "Epoch 2/3\n",
      "697/698 [============================>.] - ETA: 0s - loss: 0.3174 - accuracy: 0.8635 - binary_accuracy: 0.8635INFO:tensorflow:Assets written to: ./models/0002/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/0002/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "698/698 [==============================] - 52s 75ms/step - loss: 0.3174 - accuracy: 0.8635 - binary_accuracy: 0.8635\n",
      "Epoch 3/3\n",
      "697/698 [============================>.] - ETA: 0s - loss: 0.3088 - accuracy: 0.8669 - binary_accuracy: 0.8669INFO:tensorflow:Assets written to: ./models/0003/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/0003/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "698/698 [==============================] - 51s 73ms/step - loss: 0.3088 - accuracy: 0.8669 - binary_accuracy: 0.8669\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x117770250>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit((cat_train_selected, bin_train_selected, num_train_selected), y_train_is_installed, epochs = 3, batch_size=batch_size, callbacks=[mcp_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_models= glob.glob(chckpt_path+\"/*\") \n",
    "latest_model = max(list_of_models, key=os.path.getctime)\n",
    "# print(latest_file)\n",
    "model = tf.keras.models.load_model(latest_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(y_true, y_pred):\n",
    "    y_pred[y_pred>=0.5]=1\n",
    "    y_pred[y_pred<0.5]=0\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "    tpr = round(tp / (tp+fn),4)\n",
    "    fpr = round(tp / (fp+tn),4)\n",
    "    tnr = round(tn / (tn+fp),4)\n",
    "    fnr = round(fn / (fn+tp),4)\n",
    "    acc = round((tp + tn) / (tp+fn+fp+tn),4)\n",
    "    precision = round(tp / (tp + fp),4)\n",
    "    f1 = round(2 * (precision * tpr) / (precision + tpr),4)\n",
    "    \n",
    "    return tpr, fpr, tnr, fnr, acc, precision, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "698/698 [==============================] - 17s 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jr/974ggbdj74sczwq4lflylfy00000gn/T/ipykernel_21699/2816523072.py:14: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = round(tp / (tp + fp),4)\n"
     ]
    }
   ],
   "source": [
    "# Train predictions\n",
    "y_pred_train = model.predict((cat_train_selected, bin_train_selected, num_train_selected), batch_size=batch_size)\n",
    "tpr_train, fpr_train, tnr_train, fnr_train, acc_train, precision_train, f1_train = compute_metrics(y_train_is_installed, y_pred_train)\n",
    "\n",
    "# Train dumb predictions\n",
    "y_pred_train_dumb = np.zeros(y_train_is_installed.shape)\n",
    "tpr_train_dumb, fpr_train_dumb, tnr_train_dumb, fnr_train_dumb, acc_train_dumb, precision_train_dumb, f1_train_dumb = compute_metrics(y_train_is_installed, y_pred_train_dumb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5318, 0.112, 0.8888, 0.4682, 0.8266, 0.5018, 0.5164, 0.826)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpr_train, fpr_train, tnr_train, fnr_train, acc_train, precision_train, f1_train, acc_train_dumb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
